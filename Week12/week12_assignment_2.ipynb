{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPFIxcagHVqJ"
      },
      "source": [
        "# Week 11 Assignment\n",
        "\n",
        "\n",
        "Please do the programming exercise and verify that your code works using the tests, then think about your final project and fill out the questions in the second part.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa1LXNmPHVqL"
      },
      "source": [
        "### 47.1: Filtering and summarizing data\n",
        "\n",
        "For this work, you'll find a data file in `https://hds5210-data.s3.amazonaws.com/complications_all.csv`.\n",
        "\n",
        "Read in the data file and create a variable called `mo_hospitals` that contains a data frame from the `complications_all.csv` file, filtered down to only contain those hospitals from the state of Missouri (MO).\n",
        "\n",
        "Then aggregate that data by hospital into a variable named `mo_summary`.  There are some key fields that we want to summarize:\n",
        "* We want to know the earliest date that each hospital was participating in any program\n",
        "* We want to know the latest date that each hospital stopped participating in any program\n",
        "* We want to know the total number of patients in the denominators of these programs\n",
        "\n",
        "Some things to note:\n",
        "* You will need to convert the `Start Date` and `End Date` to actual datetime fields\n",
        "* You will need to clean up and convert the `Denominator` field to just be numeric - the rule that you should use it to simply remove any records where the `Denominator` is `'Not Available'`\n",
        "\n",
        "\n",
        "The final result of this step should be a new data frame called `mo_summary` that contains one row for each hospital and contains the min start date, max end date, and total denominator.  Use the names `start_date`, `end_date`, and `number` for those columns in `mo_summary`.\n",
        "\n",
        "\n",
        "You do not need to create your code in the form of a function, just make sure your variable names match what I've described above so the tests work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E9SNK7GiHVqM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# This is just to show you the name to use for the variable you need to create for this step to pass.\n",
        "all_hospitals = pd.read_csv('https://hds5210-data.s3.amazonaws.com/complications_all.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7kC00LHTHVqN"
      },
      "outputs": [],
      "source": [
        "\n",
        "mo_hospitals = all_hospitals[all_hospitals['State'] == 'MO'].copy()\n",
        "mo_hospitals.loc[:, 'Denominator'] = pd.to_numeric(mo_hospitals['Denominator'], errors='coerce')\n",
        "mo_hospitals = mo_hospitals.dropna(subset=['Denominator'])\n",
        "mo_hospitals.loc[:, 'Denominator'] = mo_hospitals['Denominator'].astype(int)\n",
        "mo_hospitals.loc[:, 'Start Date'] = pd.to_datetime(mo_hospitals['Start Date'], errors='coerce')\n",
        "mo_hospitals.loc[:, 'End Date'] = pd.to_datetime(mo_hospitals['End Date'], errors='coerce')\n",
        "mo_summary = mo_hospitals.groupby('Facility Name').agg(\n",
        "    start_date=('Start Date', 'min'),\n",
        "    end_date=('End Date', 'max'),\n",
        "    number=('Denominator', 'sum')\n",
        ").reset_index()\n",
        "mo_summary.set_index('Facility Name', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SwgYWHEcHVqN"
      },
      "outputs": [],
      "source": [
        "assert(mo_summary['number'].sum() == 1766908)\n",
        "assert(mo_summary['start_date'].min() == pd.Timestamp(2015,4,1))\n",
        "assert(mo_summary['end_date'].max() == pd.Timestamp(2018,6,30))\n",
        "assert(mo_summary.shape == (108,3))\n",
        "assert(mo_summary.loc['BARNES JEWISH HOSPITAL'].number == 131313)\n",
        "assert(mo_summary.loc['BOONE HOSPITAL CENTER'].number == 63099)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yESAohWnHVqO"
      },
      "source": [
        "---\n",
        "\n",
        "### 47.2 Planning your final project\n",
        "\n",
        "You should be thinking about the things we've been learning and how you can apply them to your final project.  Use the rubric to help guid your thinking and then answer the questions below.  This is meant as a guide to help you think through what you will do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh05prSDHVqO"
      },
      "source": [
        "#### A) Data Access\n",
        "\n",
        "Your project should include data from at least three distinct types of sources.  For example: AWS S3, Relational Databases, Internet, Web Services, local files.  List what data sources you're planning to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq79TSa1HVqO"
      },
      "source": [
        "I will fetch data to be used when doing my final project from at least three different sources to ensure completeness of the analysis. These include first using data sets stored on AWS S3, where these datasets shall comprise big, raw files in formats such as CSV, JSON, or Parquet, and so forth. I will be working with relational databases, like MySQL or PostgreSQL, in order to access the data they maintain and structured data principally through queries in a business application or transactional type. Then, I will combine real-time updated data that comes from web services or APIs along with weather information or applications for social media, or whatever publicly available data emanates from government websites. Lastly, I will include data from local files, such as CSV, Excel, or JSON, which I might have collected or sourced from a study, so that it is readily available to be processed. With these types of different sources of data, I can apply what I know about wrangling data, integrating, and analyzing in the project and guarantee that my project has a wide scope of data handling skills.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsUenMnKHVqO"
      },
      "source": [
        "#### B. Data Formats\n",
        "\n",
        "Your project should include data that comes in different file formats.  For example: HL7, EDI, HTML, CSV, Excel, JSON, XML.  List what data formats you're planning to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVhHEbiOHVqP"
      },
      "source": [
        "Approaches toward the final project would include working with different data formats: structured CSV or Excel files for ease of analysis and manipulation, JSON files for handling data that is maintained either by web services or APIs to allow flexibility in current data access. XML could also be used if there needs to be an exchange of structured data, especially with any integrations to a web service or external system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yht6VgRnHVqP"
      },
      "source": [
        "#### C. Objective\n",
        "\n",
        "What purpose would your project serve in a real work setting?  Take a couple of paragraphs to write down why this is an interesting product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPs1TzYHVqP"
      },
      "source": [
        "A project like mine, based on the real world, would collect information from various sources, analyze it, and hence provide useful insights. Such a project would have summarized views of complex systems or processes, taking data from AWS S3, relational databases, web services, and local files that could be used in the healthcare industry, business intelligence, or customer analytics. Having the capability to manage data coming from different sources and formats will give the organization the ability to make decisions based on facts, optimize its operations, and outline patterns and trends that otherwise may not be noticed.\n",
        "\n",
        "This project would be really interesting because working with diverse and large datasets is one of the most common challenges for any industry today. Indeed, it would represent more than just technological prowess in wrangling, aggregating, and visualization; it, in fact, would mean derivation of data from a multitude of platforms into meaningful conclusions. Such insights may underpin critical processes, improve customer experiences, or even help in predictive models for future outcomes-very valuable for any data-driven organization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcZYxjI0HVqP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Submit your work via GitHub as normal\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}